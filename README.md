# Links

Credit: https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2

# Micrograd

- A tiny Autograd (auto gradient) engine

## Backpropagation

- Recursive application of chain rules from output back to input nodes to produce gradients (derivative of output with respect to a local node)

## PyTorch define new autograd function

- https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html

- In PyTorch, you can actually define a new autograd function as long as you know the forward and backward pass formulas for this function